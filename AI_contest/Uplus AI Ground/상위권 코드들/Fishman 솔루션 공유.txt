Posted by Contents&Education
2022.12.22.17:11
 4	UP
Team Fishman
솔루션 요약

시청 이력에서 유저-아이템 빈도를 일 단위 집계로 요약하여 정의

lightGCN을 통해 유저별 아이템 선호도 학습

선호도에 아이템 인기도 점수(TOP-POP Score)를 추가하여 최종 추천 리스트 생성


사용 라이브러리

Pytorch

lightGCN 구현체는 따로 작성(TF 기반 구현체는 recommenders의 lightGCN부분  참고)

https://github.com/microsoft/recommenders/blob/main/examples/02_model_collaborative_filtering/lightgcn_deep_dive.ipynb


데이터 전처리 방식 

시청 시작 이력과 시청 종료 이력 데이터만 사용

이력 데이터는 크게 두 가지 방법으로 데이터화

User-Item Matrix :  유저가 일 단위로 경험한 아이템 횟수를 집계

ex) 03.01에 A 앨범을 30번 봤어도 1회로 입력

이는 틀어놓고 딴짓을 하는 것 같은 케이스의 과대평가를 막음과 동시에, 앨범에 대한 순수한 관심도를 표현하기 위함입니다

Top-Pop Score : 앞서 정의된 User-Item Matrix에서 콜드 스타터(ex : 3회 미만)를 정의하고, 
이 콜드 스타터들에게 아이템별 인기도 점수(아이템별 횟수 sum / Max)를 부여하여 가중치를 더함


모델 알고리즘 설명 : lightGCN

lightGCN(arXiv:2002.02126 [cs.IR])은 2020년 SIGIR conference에서 발표된 알고리즘으로, 그래프 기반 협력적 필터링(Neural Graph Collaborative Filtering, NGCF)에서 불필요한 부분을 덜어낸 가볍고 실용적인 모델입니다

모델에 User-item 경험에 관한 정보만 필요하여 간편하며, 모델의 구조 또한 NGCF/GCN 대비 
단순하여 큰 어려움 없이 재구성 및 확장이 가능하다는 장점이 있습니다


솔루션 Key Point

과제를 하며 성능향상에 중요했던 부분은 ‘반복시청’과 ‘인기 컨텐츠 시청’을 어떻게 잘 잡아내는가였습니다

이는 아동 시청자들(특히 유아)의 특징이 성인 시청자와 상이하여 나타나는 현상으로 보입니다. 

또 테스트 데이터가 학습 데이터 직후를 다루기 때문에, 시청자들이 비슷한 걸 볼 가능성이 높아 위 두 가지 포인트가 큰 역할을 하지 않았나 생각합니다

하이퍼 파라미터 튜닝은 마지막 모델 미세조정에서 성능을 올리는데 도움이 되었습니다

이러한 가중치 반영 및 튜닝과정에서 무거운 모델이였다면 테스트가 어려웠을 수도 있으나, 가볍고 튜닝이 쉬운 모델이어서 이점을 가져갔습니다


결론 및 후기

4주라는 기간, 상용성이 필요한 과제에서 lightGCN이라는 목적에 적합한 모델을 찾게 되어 프로젝트 진행이 원활했던 것 같습니다

한편으로는 Deep Factorization Machine, BiVAE 등 프로젝트 초기에  테스트해보고자 했던 알고리즘들이 제대로 성능을 내지 못해서 포기했던 부분에 대한 아쉬움이 있습니다

단기 예측을 목표로 하고 성능이 최우선이었기 때문에 성능 저하의 우려가 있는 복잡한 스코어 구조/피쳐들은 배제를 하였지만, 
다른 요소(예: 카카오가 소개한 추천 이유를 추가한 추천 알고리즘, 실 서비스 적용시 이유를 적어주는 것이 효용성이 좋았다고 함)도 
고려해볼 수 있는 모형들을 활용해서 추가로 연구해본다면 재밌을 것 같습니다