Posted by Contents&Education
2022.12.22.16:52
 1	UP
점수

Public Score: 0.2365 (6th)

Private Score: 0.1816 (5th)




사용한 모델 알고리즘

여러 알고리즘 중에서 Baseline으로 제공된 NeuMF를 최종적으로 사용했습니다.




데이터 전처리 방식 & 주요 활용된 데이터셋 피쳐

성능 향상을 위해서 추가적으로 진행한 부분은 없고 Baseline의 데이터 전처리 방식을 활용했습니다.

대신에 5-Fold 교차 검증을 위한 데이터 전처리를 진행하였고,

추가적으로 이후 앙상블 방식에서 활용하기 위해 여러 개의 데이터 셋을 생성하였습니다.

각 데이터 셋은 각각 다른 seed number로 데이터를 섞고 validation datasets을 5개로 나눠서 여러 개의 데이터 셋을 생성하였습니다.

최종적으로는 제공된 데이터 셋을 8개의 seed number로 섞어 8개의 섞인 데이터 셋이 생성되고

각각의 데이터 셋을 5-Fold 교차검증을 위한 데이터 셋으로 나눠서 최종적으로 40개의 데이터 셋을 생성하여 사용했습니다.




점수 향상 포인트

NCF 논문에 기반하여 MLP의 Layer를 추가하는 실험을 진행했습니다. 
결과적으로 기본(2 Layer)보다 3, 4 Layer에서 하이퍼 파라미터를 최적화했을 때 성능 향상이 있었습니다.



Baseline에서 Train과 Validation을 8:2로 나눠서 진행하는데, 이를 기반으로 5-Fold 교차 검증을 진행했습니다. 
결과적으로 교차검증을 진행했을 때 하이퍼 파리미터 튜닝을 진행했을 때보다 매우 큰 폭의 성능 향상이 있었습니다.


교차 검증 진행 시 5개의 데이터 셋으로 나눠서 학습을 진행하게 되는데, 각각의 데이터 셋으로 학습된 모델의 성능 편차가 
제가 생각한 기대값보다 컸습니다. 데이터 셋의 크기가 작기 때문에 발생했다고 생각하여 여러 데이터 셋에 대해 
"학습된 모델 결과를 앙상블을 진행하였습니다. 앙상블 진행 결과 교차 검증을 진행했을 때보다 더 큰 성능 향상이 있었습니다.


앙상블을 진행할 때, 각각의 모델이 데이터 셋에 공통 데이터가 적을 수록 앙상블이 더 효과적이었습니다. 
효과를 높이기 위해서 5-Fold로 데이터 셋을 생성할 때 여러 개의 seed number로 데이터 셋을 생성하는 방식을 채택하였습니다.


최종적으로 여러 모델을 앙상블 할 수록 좋은 성능을 보여주었습니다. 하지만 너무 많은 모델을 앙상블 할 경우에는 
성능 향상이 이루어 지지 않고 대신 오버 피팅되는 한계점이 있었습니다. 최종 선택은 40개의 모델 앙상블을 진행했습니다.