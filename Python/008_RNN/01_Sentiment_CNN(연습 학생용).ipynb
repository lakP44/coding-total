{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"1mvcMZjzmoye8_J2LND6mpdAib1aJTh_V","timestamp":1579181395154}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 데이터 출처\n","\n","[Naver sentiment movie corpus]: https://github.com/e9t/nsmc/\n","\n","- CNN 모델의 학습을 위해 [Naver sentiment movie corpus] 데이터셋 중 일부를 추출하여 사용하였습니다."],"metadata":{"id":"aUAzP3HKw9ic"}},{"cell_type":"code","source":["# torchtext.legacy를 사용할 수 있는 torchtext 버전 설치\n","!pip install -U torchtext==0.10.0"],"metadata":{"id":"4xlnVwtmM_0h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664096182485,"user_tz":-540,"elapsed":107486,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"eda2f432-c849-411e-f104-f3afec78be25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"ay1ouffYd02L","outputId":"53553beb-1438-413f-bebb-38b09d147597","executionInfo":{"status":"ok","timestamp":1664096211274,"user_tz":-540,"elapsed":20396,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#colab 을 이용한 실행시\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"HKiGO6t0dmZx"},"source":["import torch\n","# torch.nn : 신경망 구현을 위한 데이터 구조, 신경망 레이어, 관련함수들이 구현되어 있는 팩키지\n","# torch.nn.functional: torch.nn 팩키지의 함수들이 정의되어 있음 (손실함수, 활성화함수, 풀링함수 등) \n","# torch. autograd : 미분을 위한 함수들이 정의되어 있음\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","#import torchtext.data as data\n","#import torchtext.datasets as datasets\n","#legacy 버전으로 변경\n","\n","# torchtext : text의 preprocessing 파이프라인 정의, \n","# 토크나이징, Vocab 생성, dataset splits, 데이터 로더 등 지원\n","from torchtext.legacy import data\n","import torchtext.datasets as datasets\n","\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<연습> 3개, 4개, 5개 단어로 된 필터(커널)를 각 100개씩 적용하는 CNN 모델을 정의하여 긍부정 분류를 실행하세요.\n","\n","분류 정확도를 높일 수 있는 방법을 자유롭게 시도해 보세요."],"metadata":{"id":"lfjQ9Ta12O5g"}},{"cell_type":"code","metadata":{"id":"5M_ahOAzdmZ3"},"source":["# CNN 모델링\n","class CNN_Text(nn.Module):\n","    # 생성자 : 모델의 구조와 동작을 정의\n","    # 객체가 갖는 속성값을 초기화함. 객체가 생성될 때 자동으로 호출된다.\n","    def __init__(self, embed_num, class_num):\n","        super(CNN_Text, self).__init__() # nn.Module 클래스의 변수들을 상속\n","        # V: 사전의 크기\n","        # D: embed_dim\n","        # C: 분류하고자 하는 클래스의 개수\n","        # Co : 각 커널(필터)의 갯수\n","        V = embed_num\n","        D = 100 \n","        C = class_num\n","        \n","        #--- (연습1) Co에 output channel의 갯수를 지정하세요 ---\n","        # write code here \n","      \n","\n","        #--- (연습2) Ks에 커널사이즈(단어 갯수)를 지정하세요 ---\n","        # write code here \n","      \n","\n","        # 사전에 있는 모든 단어 벡터에 random 초기값\n","        self.embed = nn.Embedding(V, D) \n","        # torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride=1)\n","        # convs1에 컨볼루션 모듈의 리스트가 들어감 (필터(커널) 갯수만큼) \n","        # forward에서 순차적으로 접근 가능\n","        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, 100)) for K in Ks])\n","        self.dropout = nn.Dropout(0.2)\n","        # nn.Linear : Linear 레이어를 위한 클래스\n","        self.fc1 = nn.Linear(len(Ks)*Co, C)\n","\n","# foward 함수 : 모델이 학습데이터를 입력받아서 forward 연산을 진행\n","# model 객체를 데이터와 함께 호출하면 자동으로 실행된다.\n","    def forward(self, x):\n","        x = self.embed(x)  # (N, W, D) 미니배치, 문장 최대길이, 단어벡터 차원\n","        x = x.unsqueeze(1)  # (N x Ci x W x D) Conv2d를 사용하려면 채널정보 추가해야 함\n","        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks) MaxPool1D는 3D 입력만 받음\n","        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks) max pooling 후에 마지막 차원은 1 -> squeeze\n","        x = torch.cat(x, 1) # torch.cat(tensors, dim=0), dim=1이면 두번째 차원이 늘어나게 concat (첫번째 차원은 N)\n","        x = self.dropout(x)  # (N, len(Ks)*Co), dropout을 적용\n","        logit = self.fc1(x)  # fully-connected layer 적용\n","        return logit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gM4G8CnWdmZ5"},"source":["class mydataset(data.Dataset):\n","    @staticmethod\n","    def sort_key(ex):\n","        return len(ex.text)\n","    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n","        fields = [('text', text_field), ('label', label_field)] # text_field는 text로 호칭하고, label_field 필드는 label로 호칭\n","        if examples is None:\n","            path = self.dirname if path is None else path\n","            examples = []\n","            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n","                if i==0:\n","                    continue\n","                line = line.strip().split('\\t')\n","                txt = line[1].split(' ')               \n","                                  \n","                examples += [ data.Example.fromlist( [ txt, line[2]],fields ) ]\n","        super(mydataset, self).__init__(examples, fields, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWexP0_1dmZ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664096644660,"user_tz":-540,"elapsed":409,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"dac7e9a2-2ba7-46ea-d085-0ec68a2905ef"},"source":["# text_field, label_field : 전처리 관련된 field 객체를 각각 생성 \n","# batch_first : 미니배치 차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부\n","# fix_length : 하나의 문장 내 max 토큰수 \n","# sequential : 시퀀스데이터 여부\n","text_field = data.Field(batch_first = True, fix_length = 20 )\n","label_field = data.Field(sequential= False, batch_first = True, unk_token = None )\n","\n","train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt')\n","\n","test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n","#print(test_data.fields.items())\n","\n","# vocab 생성\n","text_field.build_vocab(train_data)\n","label_field.build_vocab(train_data)\n","\n","# Defines an iterator that loads batches of data from a Dataset\n","train_iter, test_iter = data.Iterator.splits(\n","                            (train_data, test_data), \n","                            batch_sizes=(100, 1))#, device= 'cuda')\n","len(text_field.vocab)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21893"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0lf4fXqhdmZ_"},"source":["# CNN모델 객체를 생성 (embed_num, class_num)\n","cnn = CNN_Text(len(text_field.vocab), 2)\n","\n","# torch.optim : 신경망 학습을 위한 다양한 파라미터 최적화 알고리즘이 구현되어 있는 팩키지\n","# Optimizer를 설정\n","optimizer = torch.optim.Adam(cnn.parameters())\n","cnn.train()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"lCPi9H_MdmaC"},"source":["for epoch in range(20):\n","    \n","    totalloss = 0\n","    for batch in train_iter:\n","        optimizer.zero_grad() # resets the gradient to 0\n","        \n","        txt = batch.text\n","        label = batch.label\n","                \n","        #print(txt.size()) -> torch.Size([100, 20])\n","        pred = cnn(txt)\n","                \n","        #print(pred.size(), label.size()) -> torch.Size([100, 2]) torch.Size([100])\n","        #print(label)\n","        loss = F.cross_entropy(pred, label)\n","        totalloss += loss.data\n","        \n","        loss.backward() # backward 연산\n","\n","        #--- (연습3) 파라미터를 업데이트 하는 함수를 호출하세요 ---\n","        # write code here\n","       \n","        \n","        \n","    print(epoch,'epoch')    \n","    print('loss : {:.3f}'.format(totalloss.numpy()))\n","\n","torch.save(cnn,'/content/gdrive/My Drive/Colab Notebooks/aivle/model/cnn_model.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EXYHemZy3m0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUApbakVdmaF"},"source":["%%time\n","from sklearn.metrics import classification_report\n","cnn.eval()\n","correct = 0\n","incorrect = 0\n","y_test = []\n","prediction = []\n","\n","for batch in test_iter:\n","    txt = batch.text\n","    label = batch.label\n","    y_test.append(label.data[0])\n","\n","    pred = cnn(txt)\n","    _,ans = torch.max(pred,dim=1)\n","    prediction.append(ans.data[0])\n","    \n","    if ans.data[0] == label.data[0]:        \n","        correct += 1    \n","    else:\n","        incorrect += 1\n","    \n","print ('correct : ', correct)\n","print ('incorrect : ', incorrect)\n","print(classification_report(torch.tensor(y_test), \n","                            torch.tensor(prediction), \n","                            digits=4, \n","                            target_names=['negative', 'positive']))\n","\n","# Weighted Avg는 클래스의 수치간의 평균 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i045lkYUdmaH"},"source":[],"execution_count":null,"outputs":[]}]}