{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"1mvcMZjzmoye8_J2LND6mpdAib1aJTh_V","timestamp":1579181395154}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 데이터 출처\n","\n","[Naver sentiment movie corpus]: https://github.com/e9t/nsmc/\n","\n","- CNN 모델의 학습을 위해 [Naver sentiment movie corpus] 데이터셋 중 10,000건을 추출하여 사용하였습니다."],"metadata":{"id":"XNAKALrMvlZC"}},{"cell_type":"code","source":["# torchtext.legacy를 사용할 수 있는 torchtext 버전 설치\n","!pip install -U torchtext==0.10.0"],"metadata":{"id":"4xlnVwtmM_0h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664919090831,"user_tz":-540,"elapsed":105737,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"3e6b50da-4c50-4afc-e7af-7cbd86723647"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"ay1ouffYd02L","outputId":"6386143f-e833-40fd-9541-2ad2dd725a61","executionInfo":{"status":"ok","timestamp":1664919214811,"user_tz":-540,"elapsed":19012,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#colab 을 이용한 실행시\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"HKiGO6t0dmZx","executionInfo":{"status":"ok","timestamp":1664919218135,"user_tz":-540,"elapsed":770,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"source":["import torch\n","# torch.nn : 신경망 구현을 위한 데이터 구조, 신경망 레이어, 관련함수들이 구현되어 있는 팩키지\n","# torch.nn.functional: torch.nn 팩키지의 함수들이 정의되어 있음 (손실함수, 활성화함수, 풀링함수 등) \n","# torch.autograd : 미분을 위한 함수들이 정의되어 있음\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","\n","# torchtext.legacy : text를 위한 데이터 로더를 제공, 다음과 같은 과정을 편리하게 지원\n","# 토크나이징(Tokenization)\n","# 단어장 생성(Build Vocabulary)\n","# 토큰의 수치화(Numericalize all tokens)\n","# 데이터 로더 생성(Create Data Loader)\n","\n","from torchtext.legacy import data\n","import torchtext.datasets as datasets\n","import pickle"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"5M_ahOAzdmZ3","executionInfo":{"status":"ok","timestamp":1664919220917,"user_tz":-540,"elapsed":7,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"source":["# CNN 모델의 구조와 연산을 정의\n","class CNN_Text(nn.Module):\n","    # 생성자 : 모델의 구조와 동작을 정의\n","    # 객체가 갖는 속성값을 초기화함. 객체가 생성될 때 자동으로 호출된다.\n","    def __init__(self, embed_num, class_num):\n","        super(CNN_Text, self).__init__() # nn.Module 클래스를 초기화\n","        # V: 사전의 크기\n","        # D: embed_dim\n","        # C: 분류하고자 하는 클래스의 개수\n","        # Co : 각 커널(필터)의 갯수\n","        V = embed_num\n","        D = 100 \n","        C = class_num\n","        Co = 50         # output channel 수 (필터의 갯수)\n","        Ks = [2,3,4]\n","\n","        # 사전에 있는 모든 단어 벡터에 random 초기값\n","        self.embed = nn.Embedding(V, D) \n","        # torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride=1)\n","        # convs1에 컨볼루션 모듈의 리스트가 들어감 (필터(커널) 갯수만큼) \n","        # forward에서 순차적으로 접근 가능\n","        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, 100)) for K in Ks])\n","        self.dropout = nn.Dropout(0.2)\n","\n","        # nn.Linear 클래스. Fully Connected Layer \n","        # Applies a linear transformation to the incoming data (y = Wx + b)\n","        # torch.nn.Linear(in_features, out_features)\n","        # in_features: size of each input sample, out_features: size of each output sample \n","        self.fc1 = nn.Linear(len(Ks)*Co, C)\n","\n","        # foward 함수 : 모델이 학습데이터를 입력받아서 forward 연산을 진행\n","        # model 객체를 데이터와 함께 호출하면 자동으로 실행된다.\n","    def forward(self, x):\n","        x = self.embed(x)   # (N, W, D) 미니배치, 문장 최대길이, 단어벡터 차원\n","        x = x.unsqueeze(1)  # (N x Ci x W x D) Conv2d를 사용하려면 입력채널 수 추가해야 함\n","\n","        # Convolution Layer\n","        # Convolution -> ReLU -> 텐서의 dimension 3을 squeeze(max_pool1d는 3D 입력을 받음)\n","        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]\n","\n","        # Max Pooling\n","        # F.max_pool1d(input, kernel_size): Applies a 1D max pooling over an input\n","        # Tensor.size(dim=None) : Returns the size of the self tensor. If dim is specified, returns the size of that dimension.\n","        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks) max pooling 후에 마지막 차원은 1 -> squeeze\n","        x = torch.cat(x, 1) # torch.cat(tensors, dim), dim=1이면 두번째 차원이 늘어나게 concat (첫번째 차원은 N)\n","        x = self.dropout(x) # (N, len(Ks)*Co), dropout을 적용\n","        logit = self.fc1(x) # fully-connected layer 적용\n","        return logit"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gM4G8CnWdmZ5","executionInfo":{"status":"ok","timestamp":1664919224752,"user_tz":-540,"elapsed":302,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"source":["class mydataset(data.Dataset):\n","    @staticmethod  # 유틸리티 메소드 정의 시 선언\n","    def sort_key(ex):\n","        return len(ex.text)\n","    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n","        fields = [('text', text_field), ('label', label_field)] # text_field 레이블은 text, label_field 레이블은 label\n","        if examples is None:\n","            path = self.dirname if path is None else path\n","            examples = []\n","            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n","                if i==0:\n","                    continue\n","                line = line.strip().split('\\t')\n","                txt = line[1].split(' ')               \n","                                  \n","                examples += [ data.Example.fromlist( [ txt, line[2]],fields ) ]\n","        super(mydataset, self).__init__(examples, fields, **kwargs)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWexP0_1dmZ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664919229325,"user_tz":-540,"elapsed":1875,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"103d01f2-b4db-4dcd-816a-719c67892d3e"},"source":["# Field : 텐서로 변환될 텍스트 데이터타입을 정의 \n","# text_field, label_field : 전처리 관련된 field 객체를 각각 생성 \n","# batch_first : 미니배치 차원을 맨 앞에 둔 텐서를 생성할 것인지\n","# fix_length : 하나의 문장 내 max 토큰수 \n","# sequential : 시퀀스 데이터 여부\n","text_field = data.Field(batch_first = True, fix_length = 20)\n","label_field = data.Field(sequential= False, batch_first = True, unk_token = None) # unk_token을 표현할 스트링\n","\n","train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt')\n","\n","test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n","#print(test_data.fields.items())\n","\n","# vocab 생성\n","text_field.build_vocab(train_data)\n","label_field.build_vocab(train_data)\n","\n","# Data Loader 생성 (train_data, test_data를 각각 100개, 1개씩 데이터 로딩)\n","train_iter, test_iter = data.Iterator.splits(\n","                            (train_data, test_data), \n","                            batch_sizes=(100, 1))#, device= 'cuda')\n","len(text_field.vocab)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21893"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0lf4fXqhdmZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664919232890,"user_tz":-540,"elapsed":364,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"cb4c6c7f-d73c-4eb8-c44f-110d618f1f03"},"source":["# CNN모델 객체를 생성 (embed_num, class_num)\n","cnn = CNN_Text(len(text_field.vocab),2)\n","\n","# torch.optim : 신경망 학습을 위한 다양한 파라미터 최적화 알고리즘이 구현되어 있는 팩키지\n","# Optimizer를 설정\n","optimizer = torch.optim.Adam(cnn.parameters())\n","cnn.train()\n"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN_Text(\n","  (embed): Embedding(21893, 100)\n","  (convs1): ModuleList(\n","    (0): Conv2d(1, 50, kernel_size=(2, 100), stride=(1, 1))\n","    (1): Conv2d(1, 50, kernel_size=(3, 100), stride=(1, 1))\n","    (2): Conv2d(1, 50, kernel_size=(4, 100), stride=(1, 1))\n","  )\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc1): Linear(in_features=150, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"lCPi9H_MdmaC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664919346812,"user_tz":-540,"elapsed":109985,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"6b0415a9-93ae-480a-d381-65e306da074f"},"source":["for epoch in range(20):\n","    \n","    totalloss = 0\n","    for batch in train_iter:\n","        optimizer.zero_grad() # resets the gradient to 0\n","        \n","        txt = batch.text\n","        label = batch.label\n","                \n","        #print(txt.size()) -> torch.Size([100, 20])\n","        pred = cnn(txt)\n","                \n","        #print(pred.size(), label.size()) -> torch.Size([100, 2]) torch.Size([100])\n","        #print(label)\n","        loss = F.cross_entropy(pred, label)\n","        totalloss += loss.data\n","        \n","        loss.backward() # backward 연산\n","        optimizer.step() # 파라미터 업데이트\n","        \n","    print(epoch,'epoch')    \n","    print('loss : {:.3f}'.format(totalloss.numpy()))\n","\n","torch.save(cnn,'/content/gdrive/My Drive/Colab Notebooks/aivle/model/cnn_model.pt')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["0 epoch\n","loss : 67.464\n","1 epoch\n","loss : 53.382\n","2 epoch\n","loss : 43.023\n","3 epoch\n","loss : 34.345\n","4 epoch\n","loss : 25.771\n","5 epoch\n","loss : 19.873\n","6 epoch\n","loss : 14.961\n","7 epoch\n","loss : 11.539\n","8 epoch\n","loss : 9.708\n","9 epoch\n","loss : 8.034\n","10 epoch\n","loss : 5.968\n","11 epoch\n","loss : 5.123\n","12 epoch\n","loss : 4.450\n","13 epoch\n","loss : 3.768\n","14 epoch\n","loss : 3.137\n","15 epoch\n","loss : 3.114\n","16 epoch\n","loss : 2.382\n","17 epoch\n","loss : 2.329\n","18 epoch\n","loss : 2.177\n","19 epoch\n","loss : 2.209\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"32-nf3Je68OE"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUApbakVdmaF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664919751467,"user_tz":-540,"elapsed":289,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"647d6f15-8b99-4653-bd2e-9594792b110d"},"source":["%%time\n","from sklearn.metrics import classification_report\n","cnn.eval() # 모델을 evaluation mode로 설정. 정규화 기술(dropout 등)을 배제하여 온전한 모델로 평가\n","correct = 0\n","incorrect = 0\n","y_test = []\n","prediction = []\n","\n","for batch in test_iter:\n","    txt = batch.text\n","    label = batch.label\n","    y_test.append(label.data[0])\n","\n","    pred = cnn(txt)\n","    _,ans = torch.max(pred,dim=1) # dimension을 기준으로 (최대값, 최대값이 있는 인덱스) 반환 \n","    prediction.append(ans.data[0]) # ans.data[0]: 최대값이 들어있는 인덱스 (0 또는 1) \n","  \n","    if ans.data[0] == label.data[0]:        \n","        correct += 1    \n","    else:\n","        incorrect += 1\n","    \n","print ('correct : ', correct)\n","print ('incorrect : ', incorrect)\n","print(classification_report(torch.tensor(y_test),     # 정답값\n","                            torch.tensor(prediction), # 예측값\n","                            digits=4,                 # 출력할 자리수\n","                            target_names=['negative', 'positive'])) # display names matching the label\n","\n","# Weighted Avg는 클래스의 수치간의 평균 "],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["correct :  78\n","incorrect :  22\n","              precision    recall  f1-score   support\n","\n","    negative     0.8500    0.6800    0.7556        50\n","    positive     0.7333    0.8800    0.8000        50\n","\n","    accuracy                         0.7800       100\n","   macro avg     0.7917    0.7800    0.7778       100\n","weighted avg     0.7917    0.7800    0.7778       100\n","\n","CPU times: user 73.9 ms, sys: 2.02 ms, total: 75.9 ms\n","Wall time: 75 ms\n"]}]},{"cell_type":"code","metadata":{"id":"i045lkYUdmaH"},"source":[],"execution_count":null,"outputs":[]}]}